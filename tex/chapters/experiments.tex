\chapter{Experiments and Results}
\label{cha:experiments}

Three experiments were conducted in this specialization project. \Autosectionref{sec:experimental-plan-and-setup} will explain how the experiments were conducted, and \autoref{sec:experimental-results}.

\section{Method: Experimental Plan and Setup}
\label{sec:experimental-plan-and-setup}

\begin{comment}
Trying and failing is a major part of research. However, to have a chance of success you need a plan driving the experimental research, just as you need a plan for your literature search. Further, plans are made to be revised, and this revision ensures that any further decisions made are in line with the work already completed.

The plan should include what experiments or series of experiments are planned and what questions the individual or set of experiments aim to answer. Such questions should be connected to your research questions, so that in the evaluation of your results you can discuss the results wrt to the research questions.

Results should be clearly displayed and should provide a suitable representation of your results for the points you wish to make.
Graphs should be labelled in a legible font. If more than one result is displayed in the same graph, then these should be clearly marked.
Please choose carefully rather than presenting every result. Too much information is hard to read and often hides the key information you wish to present. Make use of statistical methods when presenting results, where possible to strengthen the results.
Further, the format of the presentation of results should be chosen based on what issues in the results you wish to highlight.
You may wish to present a subset in the experimental section and provide additional results in an appendix.
Point out specifics here but save the overall/general discussion to the Discussion chapter.
\end{comment}

The experiments were conducted in order to answer the research questions listed in \autoref{sec:goals-and-research-questions}. As \autoref{cha:related-work} shows, there have been a substantial body of work on mapping the geospatial abilities of \acrshortpl{acr:llm} like ChatGPT, and how these can be used to create larger frameworks for \acrshort{acr:gis} purposes. However, no literature was found that specifically discussed how \acrshortpl{acr:llm} handle geospatial files like \acrshort{acr:gml} or shapefiles, or how \acrshortpl{acr:llm} can be used to access web \acrshortpl{acr:api} that conform to common geospatial \acrshort{acr:api} standards like the \acrshort{acr:ogc} \acrshort{acr:api} Features specification. The experiments seek to address these points, with experiment 1 focusing on \rqref{rq:llm-potential} and ChatGPT's abilities of performing geospatial analysis using different file formats, while experiment 2 and 3 focus \rqref{rq:overlay-analysis} and \rqref{rq:external-tools} and on its ability to access external web \acrshortpl{acr:api}.

\subsection{Experiment 1: Testing ChatGPT's Ability to Perform Geospatial Analysis}

Experiment 1 was performed to assess ChatGPT's ability to perform geospatial analysis, and is aimed at \rqref{rq:llm-potential}. The approach used is inspired by the work of \cite{robertsGPT4GEOHowLanguage2023} (see \autoref{sec:gis-with-llms}), who did experiments with increasing difficult on \acrshort{acr:gpt}-4 to characterize what \acrshort{acr:gpt}-4 knows about the geographical world, highlighting both capabilities and limitations. \citeauthor{robertsGPT4GEOHowLanguage2023} focused on \acrshort{acr:gpt}-4's general geospatial awareness, and were not concerned with \acrshort{acr:gis}-related tasks. The reference to \cite{robertsGPT4GEOHowLanguage2023} will therefore be made when highlighting the somewhat surprising geospatial awareness abilities of GPT-4. The focus of this experiment will instead be on displaying its potential for use in the world of \acrshort{acr:gis}. This will be achieved by constructing various tests that aim to reflect its GIS knowledge.

The experiment will use the Elveg 2.0 dataset \citep{thenorwegianmappingauthorityElveg2019}, along with cadastral data. In order to assess ChatGPT's ability to read and understand different data formats, the data will be provided in both \acrshort{acr:sosi}, \acrshort{acr:gml}, and GeoJSON format. Datasets for the first two formats were downloaded from \url{https://geonorge.no}, while the GeoJSON datasets were created using a custom Bash script which converts from \acrshort{acr:gml} to GeoJSON using the \texttt{ogr2ogr} program from \acrshort{acr:gdal}. The Elveg 2.0 dataset contains a range of different layers for different types of geometries. In order to simplify the experiments, only the layer named "Fartsgrense" (eng. "Speed limit") was used from Elveg 2.0.

Below are the questions that were asked, in rising order of predicted complexity:

\begin{enumerate}
    \item \enquote{Provide a summary of the file contents, highlighting the file's most salient features.}
    \item \enquote{Provide a visual representation of the file contents.}
    \item \enquote{Find the mean location of the building locations.}
    \item \enquote{Extract all roads with a speed limit greater than or equal to 80 km/h.}
    \item \enquote{Select all buildings located within 50 metes of a high-speed road (speed limit >= 80 km/h).}
    \item \enquote{Find the area best suited for expansion to accommodate residential buildings.}
\end{enumerate}
\label{enum:gpt-gis-questions}

Some follow-up questions are added when needed, in order help the model understand the questions or when it stops and asks for permission to go forth with analysis. All conversations are saved in the project's GitHub repository\footnote{\url{https://github.com/oskarhlm/prosjektoppgave/tree/main/documents/ChatGPT_conversations}}.

\subsection{Experiment 2: Comparing File Upload and API Calling in ChatGPT-4}

Another important thing to test is the issue of providing ChatGPT with relevant files on which it can perform analysis. ChatGPT Plus users will have access a range of advanced features, including web browsing with Bing, Dall-E Image Generation, and Code Interpreter (or Advanced Data Analysis). The latter of these allows the user to manually upload files into the chat instance and perform advanced analyses on the contents of these, which is what was used to upload the datasets in experiment 1. While this is very powerful, having to manually upload files poses some limitations. A more flexible system should be capable of accessing web \acrshortpl{acr:api} in real time.

A dataset containing the border of Drammen Municipality was used to test compare ChatGPT's ability to perform analyses on manually uploaded data, versus data handed through it from passing a URL address. The data conforms to the GeoJSON standard and contains a FeatureCollection object with a single Feature, namely the border. When file/URL has been provided, ChatGPT is simply asked to present a visual presentation of its contents.

The dataset is located under this web \acrshort{acr:api}: \url{https://alenos-tester001.azurewebsites.net/}. This example \acrshort{acr:ogc} \acrshort{acr:api} was created by Norkart's Alexander Salveson Nossum for with the purpose of testing \acrshort{acr:ogc} \acrshort{acr:api} Features on Norwegian data. It was created using \texttt{pygeoapi}\footnote{\url{https://pygeoapi.io/}}, which is a Python server implementation of the \acrshort{acr:ogc} \acrshort{acr:api} suite of standards. It allows for deployment of a RESTful \acrshort{acr:ogc} \acrshort{acr:api} endpoint using OpenAPI, GeoJSON, and HTML.

\subsection[Experiment 3: Using ChatGPT's and LangChain to perform API Call]{Experiment 3: Using ChatGPT's and LangChain to perform \acrshort{acr:api} Call}

A final and third experiment was conducted to see if there are other, more programmatic ways of performing \acrshort{acr:api} calls using \acrshortpl{acr:llm}. The LangChain framework \citep{chaseLangChain2022} was used to create OpenAI functions that can be called using Function Calling from OpenAI. The goal of the experiment was to produce the same plot as requested in experiment 2 using the same \acrshort{acr:api} endpoint.

One function was made to fetch the data from the \acrshort{acr:api} and save it to a temporary file on the machine from which the code is executed. Another function was made to load a GeoJSON file and plot the contents using the Matplotlib library. The hope is that, using LangChain's \texttt{AgentExecutor}, which allows reasoning and chaining responses from an \acrshort{acr:llm}, along with the Function Calling abilities of the OpenAI \acrshort{acr:gpt} \acrshortpl{acr:api}, should make it possible for the agent to call these functions in the right order and with the correct arguments. The \texttt{gpt-4-1106-preview} model was used for this experiment.

\section{Experimental Results}\label{sec:experimental-results}

\subsection{Results for Experiment 1}\label{subsec:experiment-1-results}

\begin{table}
    \centering
    \begin{tabular}{l|p{0.1\textwidth}p{0.15\textwidth}p{0.15\textwidth}p{0.15\textwidth}}
        \toprule
                               & \textbf{\acrshort{acr:sosi}} & \textbf{GML} & \textbf{GeoJSON} & \textbf{Shapefile} \\
        \midrule
        Summary                & No                           & Yes          & Partially        & Partially          \\
        Plotting               & -                            & When guided  & When guided      & Yes                \\
        Mean location          & -                            & When guided  & Yes              & No                 \\
        Filtering              & -                            & No           & Yes              & Yes                \\
        Buffer + Intersect     & -                            & No           & No               & No                 \\
        Planning for expansion & -                            & No           & Partially        & No                 \\
        \bottomrule
    \end{tabular}
    \caption{Overview of the ability of ChatGPT's Code Interpreter to handle various geospatial data formats}
    \label{tbl:data-format-tests}
\end{table}

As \autoref{tbl:data-format-tests} shows, ChatGPT's Code Interpreter is unable to read and write \acrshort{acr:sosi} files. It was unable to manipulate the data directly and was also unable to convert the file into a more suitable format, failing to convert it to GeoJSON using \acrshort{acr:gdal}'s \texttt{ogr2ogr}. \acrshort{acr:sosi} is therefore excluded from \autoref{tbl:data-format-tests}, which shows the test results on the different file formats.

Furthermore, ChatGPT's Code Interpreter did not manage to properly analyze the \acrshort{acr:gml} data without guidance. It created a parser that was difficult to use for further analysis. When guided into using the GeoPandas library, which can handle \acrshort{acr:gml} data, it managed to plot the contents and calculate a centroid. The buffering and intersection task \enquote{was interrupted due to its time-consuming nature}, and it did not make an attempt at solving the planning task due to inability to analyze the \acrshort{acr:gml} files.

With the GeoJSON data, ChatGPT had difficulties reading the files and could not provide a good summary consistently. It \textit{was} however able to plot the data, but that had to be done in separate responses for each of the two datasets. It was able to find the high-speed roads, but could not figure out which buildings were within a 50-meter buffer of these. However, when asked to plan for expansion to accommodate residential buildings, it managed to achieve a result close to what was expected in the "Buffer + Intersect" task. It accomplished this by creating a grid and figuring out which grid cells were within 50 meters of a high-speed road. While this did not extract a subset of the building points---which would have been the desired output---it had some minor value in terms of visualization (see \autoref{fig:planning-plot-from-geojson}). Though the result is hardly useful, it is closer than in the \acrshort{acr:gml} attempt to what would be an acceptable response.

Using the shapefile formatted data, ChatGPT was able to produce a decent summary of the data, but the attribute names were cut off after about 10 characters. It was, however, able to produce quite good visual representations of both dataset, colouring the roads differently by their speed limits and the buildings by their building type. While it did manage to filter roads on speed limits, it could not calculate the mean location of the buildings. The buffer + intersection and planning tasks again proved too complex.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{../figs/residential_expansion_areas_map.png}
    \caption{The result of ChatGPT when asked to \enquote{Find the area best suited for expansion to accommodate residential buildings}, using provided GeoJSON datasets. Potentially suitable areas for residential expansion  are depicted in blue.}
    \label{fig:planning-plot-from-geojson}
\end{figure}

\subsection{Results for Experiment 2}\label{subsec:experiment-2-results}

\autoref{subfig:drammen-outline-file-upload} and \autoref{subfig:drammen-outline-api} shows the results when providing ChatGPT-4 with the GeoJSON for the outline of Drammen municipality using the file upload functionality and providing it and URL to an \acrshort{acr:api} endpoint, respectively. While the Code Interpreter handled the direct file upload with ease, it struggled when provided with the URL to the corresponding web \acrshort{acr:api}. When provided with the URL, its first response was that \enquote{there was a problem with establishing a connection to the website}, after trying to process the request using Code Interpreter. When guided (twice) to try accessing the URL using its web browsing abilities, it was eventually able to read the data. In the subsequent prompt it was asked to provide a visual representation, but failed to do so successfully as \autoref{subfig:drammen-outline-api} shows. The reason for this was its decision to \enquote{truncate the dataset for brevity, using a subset of the full coordinate list} (see \autoref{lst:python-for-failed-drammen-outline}).

\begin{figure}
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{../figs/drammen_outline_file_upload.png}
        \caption{File upload}
        \label{subfig:drammen-outline-file-upload}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{../figs/drammen_outline_api.png}
        \caption{Providing URL}
        \label{subfig:drammen-outline-api}
    \end{subfigure}
    \caption{Comparison of the resulting outline of Drammen when using file upload (\subref{subfig:drammen-outline-file-upload}) and providing an URL to an API endpoint (\subref{subfig:drammen-outline-api}) with ChatGPT-4}
    \label{fig:file-upload-api-comparison}
\end{figure}

\begin{minipage}{\linewidth}
    \begin{lstlisting}[style=python, caption=ChatGPT code that truncates coordinates, label=lst:python-for-failed-drammen-outline]
# ...

# Extracted coordinates from the JSON data
coordinates = [
    [[9.976278541184014, 59.71166107645171], [9.975715936016496, 59.71206324390201], [9.975270250797282, 59.71243147807226], 
    # ... Truncated for brevity, using a subset of the full coordinate list
    [9.964929990238785, 59.774609947672644]]
]

# ...
\end{lstlisting}
\end{minipage}

\subsection{Results for Experiment 3}\label{subsec:experiment-3-results}

The \texttt{AgentExecutor} with the \texttt{gpt-4-1106-preview} was able to call the two functions in the correct order and with the correct arguments. \autoref{fig:drammen-plot-langchain} show the resulting plot. The notebook used for the experiment is available on the project GitHub repository\footnote{\url{https://github.com/oskarhlm/prosjektoppgave/blob/main/src/python/examples/drammen_ogc_test/drammen_ogc_test.ipynb}}.

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{../figs/drammen_plot_langchain.png}
    \caption{Outline of Drammen using LangChain and OpenAI Functions}
    \label{fig:drammen-plot-langchain}
\end{figure}

\glsresetall
